\documentclass{article}
\usepackage{tabularx, resume, times}

% define the various dimensions
%\setlength{\oddsidemargin}{0pt}
%\setlength{\evensidemargin}{0pt}
%\setlength{\topmargin}{0pt}
%\setlength{\marginparwidth}{0pt}
%\setlength{\headheight}{0pt}
%\setlength{\headsep}{0pt}
%\setlength{\textheight}{10in}
\setlength{\textwidth}{6.3in}
%\setlength{\parindent}{0pt}
%\setlength{\parsep}{20pt}
%\setlength{\footskip}{0pt}
%\setlength{\voffset}{-0.5in}

\thispagestyle{empty}
% \pagestyle{fancy}

% \lfoot{} \rfoot{} \cfoot{}
% \lhead{} \rhead{} \chead{}

\begin{document}
  % put the name at the top
  \Large
  \textbf{Murali N. Vilayannur}
  % address
  \newline
  %\vspace*{6pt}
  \vspace*{0.02truein}
  \small
  \begin{tabularx}{\linewidth}{XX}
	&\\
	7351 S Woodward Avenue, Apt 307, Woodridge, IL 60517 & Phone: H: 630-748-0057 \\
  	9700 S Cass Avenue, D-239, Building 221, Argonne National Labs, Argonne, IL 60439 & Phone: O: 630-252-7198\\
  	http://www.cse.psu.edu/\verb1~1vilayann/ & e-mail: vilayann\verb1@1mcs.anl.gov 
  \end{tabularx}
  %\noindent\rule{\textwidth}{0.4mm}
  \vspace*{0.01truein}
  \hrule
  \normalsize
  \vspace*{6pt}
  
  % Research Interests

  \vspace*{-0.1truein}
  \large \textbf{Research Interests}
  \normalsize
  \vspace*{-0.1truein}
  \begin{center}
  \begin{tabularx}{6.2in}{X}
	High-Performance Input/Output Storage Systems, File Systems, Compilers and Programming Languages, Operating Systems, Data structures and algorithms for I/O.
  \end{tabularx}
  \end{center}


  % Education

  \vspace*{-0.1truein}
  \large \textbf{Education}
  \normalsize
  \vspace*{-0.2truein}
  \begin{center}
  \begin{tabularx}{6.2in}{Xr}
%  \item
	\emph {Postdoctoral Staff} & Aug 05 - Present \\
	\small
	Mathematics and Computer Science Division, & \\
	\textbf{Argonne National Laboratory}, Argonne, IL, USA. &\\
	Supervisors: Dr. Rajeev Thakur \emph{\&} Dr. Robert Ross & \\
	\normalsize
	\vspace*{0.01in}

	\emph {Doctor of Philosophy} & Aug 99 - Aug 05\\
	\small
	Computer Science \emph{\&} Engineering,& \\
	Thesis title: Runtime Support for Effective Memory Management in Large-scale Applications,&\\
	\textbf{Pennsylvania State University}, State College, PA, USA. &\\
	Advisors: Dr. Anand Sivasubramaniam \emph{\&} Dr. Mahmut Kandemir & \\
	\normalsize
	\vspace*{0.01in}

	\emph {Bachelor of Technology} & May 95 - July 99\\
	\small
	Department of Computer Science \emph{\&} Engineering, &\\
	\textbf{Institute of Technology - BHU}, Varanasi, India & \\
	GPA: 9.59/10 & \\
	\normalsize
  \end{tabularx}
  \end{center}

  % Experience
  \vspace*{-0.05truein}
  \large \textbf{Experience}
  \normalsize
%  \vspace*{-0.2truein}

  \begin{center}

	\normalsize
	\begin{tabularx}{6.2in}{Xr}
	\vspace*{-0.09truein}
	\emph{Postdoctoral Staff, Mathematics \& Computer Science Division,} & Aug 05 - present \\
	\emph{Research Aide, Mathematics \& Computer Sciences Division,} & May 04 - Aug 04	\\
	\emph{Argonne National Laboratory, Argonne, IL 60439} & Jun 02 - Dec 02 \\
	\vspace*{-2pt}
	\begin{itemize}
	\small
	\item {As part of an ongoing research effort, I am investigating performance trade-offs due to 
	aggressive file system caching and consistency semantics dictated by application needs and looking
	at meaningful ways of expressing consistency requirements that can be exploited by the underlying
	parallel file system (PVFS2, CAPFS).} 
	\item {Prior projects in the past explored techniques to enhance the performance and isolate 
	potential bottlenecks in the POSIX I/O 
	interface implementation of a parallel file system (PVFS).} 
	\end{itemize}
	\end{tabularx}

%	\vspace*{-0.12truein}
	\normalsize
	\begin{tabularx}{6.2in}{Xr}
	\emph{Research Assistant, Computer Systems Research Lab,} & May 01 - Aug 05 \\
	\emph{Pennsylvania State University, State College, PA 16802}  & May 00 - Aug 00 \\
	\vspace*{-2pt}
	\begin{itemize}
	\small
	\item {As part of my thesis research, I investigated run-time system support for effective
	 buffer management of large-scale scientific applications. More specifically, I have
	 looked at efficient caching and replacement algorithms for explicitly I/O intensive
	 and scaled versions of in-core applications.}
	\end{itemize}
	\end{tabularx}

	
%  	\vspace*{-0.12truein}
  	\normalsize
	\begin{tabularx}{6.2in}{Xr}
	\emph{Teaching Assistant, Dept. of Computer Science \& Engineering,} & Aug 00 - May 01	\\
	\emph{Pennsylvania State University, State College, PA 16802} & Aug 99 - May 00 \\
	\vspace*{-2pt}
	\begin{itemize}
	\small
	\item {Graded and evaluated project assignments for both graduate and undergraduate level courses on 
	operating system design.}
	\item {Instructed a sophomore level course on Digital logic design and a freshmen level course on 
	programming in C++.}
	\end{itemize}
	\end{tabularx}

  \end{center}

  % Publications

  \vspace*{-0.2truein}
  \large \textbf{Publications}
  \normalsize
  \vspace*{-0.2truein}

  \begin{center}
  \begin{tabularx}{6.2in}{X}
	\vspace*{0.01in}
  {\bf Murali Vilayannur}, Anand Sivasubramaniam, Mahmut Kandemir.
  Anticipatory Memory Management for Scientific Applications: A Characterization,
  \emph {In submission to IEEE Transactions on Computers.}.\\
	\vspace*{0.01in}
  {\bf Murali Vilayannur}, Mahmut Kandemir, Anand Sivasubramaniam.
  Synergic Scheduling for Memory-intensive Applications,
  \emph {In submission}.\\
  \vspace*{0.01in}
  {\bf Murali Vilayannur}, Partho Nath, Anand Sivasubramaniam.
  Providing Tunable Consistency for a Parallel File Store,
  \emph {Proceedings of the Fourth USENIX Conference on File and Storage Technologies,
  FAST'05}.\\
   \vspace*{0.01in}
   {\bf Murali Vilayannur}, Anand Sivasubramaniam, Mahmut Kandemir.  
	Pro-active Page Replacement Algorithm for Scientific Applications: A Characterization, 
	\emph {Proceedings of the 2005 IEEE International Symposium on Performance Analysis of Systems and
	Software, ISPASS'05}. \\
   \vspace*{0.01in}
   {\bf Murali Vilayannur}, Robert Ross, Philip Carns, Rajeev Thakur, Anand Sivasubramaniam,
	Mahmut Kandemir. On the Performance of the POSIX I/O interface to PVFS,  \emph{Proceedings
	of the 12$^{th}$ Euromicro Workshop on Parallel, Distributed, and Network-Based Processing, PDP
	2004.} \\
   \vspace*{0.01in}
	{\bf Murali Vilayannur}, Anand Sivasubramaniam, Mahmut Kandemir, Rajeev Thakur, Robert Ross.
	Discretionary Caching for I/O on clusters, \emph{To appear in Cluster Computing: The Journal of
	Networks, Software Tools and Applications.} \\
   \vspace*{0.01in}
	{\bf Murali Vilayannur}, Anand Sivasubramaniam, Mahmut Kandemir, Rajeev Thakur, Robert Ross.
	Discretionary Caching for I/O on clusters, \emph{Proceedings of the IEEE/ACM
	International Conference on Cluster Computing and Grid, CCGrid 2003.} \\
   \vspace*{0.01in}
   {\bf Murali Vilayannur}, Mahmut Kandemir, Anand Sivasubramaniam. 
   Kernel-level Caching for I/O by exploiting Inter-Application Data Sharing, \emph{Proceedings of
   the IEEE International Conference on Cluster Computing, CLUSTER 2002.} \\
   \vspace*{0.01in}
   K. K. Shukla, R. K. Biswal, {\bf V. N. Murali}, D. Venkatesh, R. N. Mukherjee. 
	On Some New Improved Algorithms for Digital Watermarking, \emph{Proceedings of the 4$^{th}$
	International Conference on Advances in Pattern Recognition and Digital Techniques, ICAPRDT 1999.} \\
	\end{tabularx}
  \end{center}


  % Course Background

  \vspace*{-0.1truein}
  \large \textbf{Course work}
  \vspace*{-0.2truein}
  \normalsize
  \begin{center}
  \begin{tabularx}{6.2in}{X}
        Operating Systems Design, Optimizing Compilers, Database Management Systems, Multiprocessor Architectures, Design and Analysis of Algorithms, Digital Systems Design, Component-Based Software Engineering, Distributed Systems, Science of Computer Programming, Computer Networks, Combinatorial Optimization. \\
  \end{tabularx}
  \end{center}

  % Projects

  \vspace*{-0.1truein}
  \large \textbf{Projects}
  \vspace*{-0.2truein}
  \normalsize
  \begin{center}
  \begin{itemize} 
  \item {Designed and implemented a Relational Database Management System (as a group project)
  			with distributed resource managers that supported 2-Phase locking, transactions and 
			log-based crash recovery as part of a course project(C).
		  }
  \item {Designed and implemented a User-level Threads Library package for Solaris using kernel-aware 
  		   entities (LWP's), similar to the Pthreads/Solaris thread library interface as part of a
			graduate level course on Operating Systems(C).
		  }
  \item {Implemented a Remote Procedure Call Mechanism similar to the Sun RPC package using the 
  			Pthreads library and sockets API on Solaris as part of a graduate level course on 
			Operating Systems(C).
		  }
  \item {Developed an execution-driven simulator that simulates a cc-NUMA machine's (SGI-Origin)
  			memory system that can be used to investigate the performance of parallel applications as 
			part of a graduate level course on Multiprocessor architectures(C).
		  }
  \item {Designed and implemented new algorithms for demonstrating Steganography, i.e. hiding text 
 		   in images (as a group project) as part of an under-graduate thesis(Visual C++).
		  }
  \item {Implemented a type-inference engine for an extension of lambda calculus for a graduate 
  		   level course on logic programming(Lambda Prolog).}
  \end{itemize}
  \end{center}

  % Professional Activities

	\vspace*{-0.1truein}
	\large \textbf{Professional Activities}
	\normalsize
	\vspace*{-0.2truein}
	\begin{center}
	\begin{itemize}
	\item{Program Committee Member ICPADS 2006, CLUSTER 2006.}
	 \item{Reviewer for ICPP 2000, CAC Workshop 2002, CASES 2002, CLUSTER 2002, CLUSTER 2003, HiPC 2003,
	 ICPADS 2004, IEEE-Transactions on Parallel and Distributed Systems,
	 IEEE Transactions on Computers, ACSAC 2004, HPCA (2004, 2005, 2006), ICPP (2000, 2005).}
	 \item{Member of IEEE \emph{\&} ACM.}
	\end{itemize}
	\end{center}

  % Achievements and Honors

  \vspace*{-0.1truein}
  \large \textbf{Honors/Awards}
  \normalsize
  \vspace*{-0.2truein}
  \begin{center}
  \begin{itemize}
  \item {Best Research Assistant Award, Department of Computer Science \& Engineering, Penn State, 2005}
  \item {University Gold Medal for $1^{st}$ rank in Undergraduate Computer Science Batch of 1999 at IT-BHU.}
  \item {Recipient of the prestigious J. N. Tata Endowment for Higher Education 1999.} 
  \item {Received University Merit award for academic excellence in 1996, 1998, 1999 at IT-BHU.}
  \item {Ranked in the top 1\% of over 0.1 million candidates who appeared for the Joint Entrance 
  Examination for admission to the IIT's and IT-BHU, India.}
  \end{itemize}
  \end{center}


  % Computer Skills
  \vspace*{-0.1truein}
  \large \textbf{Computer Skills}
  \normalsize
  \vspace*{-0.2truein}
  \begin{center}
  \begin{itemize}
	\item {\textbf{Programming Languages:} -- C, C++, Java, Pascal, Prolog, SML, SPARC Assembly}
	\vspace*{-0.1truein}
	\item {\textbf{Operating Systems and Platforms:} -- Unix(Linux, Solaris), Proficient with Linux
	kernel internals.}
	\vspace*{-0.1truein}
	\item {\textbf{Hardware:} -- SPARC, Intel X86.} 
	\vspace*{-0.1truein}
	\item {\textbf{Other Tools:} -- MPI, MPI-IO, SUIF, CSIM, MATLAB, Lex, Yacc.}
  \end{itemize}
  \end{center}

    
  % References
  \vspace*{-0.1truein}
  \large \textbf{References}
  \vspace*{-0.2truein}
  \normalsize
  \begin{itemize}
  \item{Dr. Anand Sivasubramaniam.}
  \item{Dr. Mahmut Kandemir.}
  \item{Dr. Rajeev Thakur.}
  \end{itemize}

  % Research Statement
	\vspace*{-0.1truein}
	\large \textbf{Research Statement}
	\normalsize

Clusters of workstations are rapidly emerging as cost-effective solutions for 
delivering high performance for many scientific applications. In these 
architectures, not only do the multiple CPUs provide for the processing 
parallelism, the multiple disks on each workstation can provide for the much 
needed storage-level parallelism for data access and transfer. Parallel file 
systems seek to harness the storage capacities and bandwidths of all the disks of a cluster 
and hide the I/O bottlenecks from such applications. 

My research interests have largely focused on caching and consistency
algorithms for parallel file-systems especially in the context of high-performance
scientific computing applications. With little or no information about the workloads to be supported,
traditional approaches to file-system designs have always adopted
a one-glove-fits-all approach in dealing with caching and consistency semantics.
Contrary to the conventional wisdom of separating mechanisms and policies for system
design, parallel file-systems impose caching policies and consistency semantics for all applications. 
Taking an inflexible stance on caching or consistency can demote throughput, latency and scalability
for such applications. My research addresses this important
problem of separating mechanisms and policies for caching and consistency policies
and using application-level access pattern information to exploit these mechanisms for efficient
performance. In many instances, such access pattern information can be automatically
gleaned by a compiler or inferred by the runtime system (middleware libraries) and in some
cases the onus is on application designers or system administrators to make use
of the mechanisms for better performance and scalability. 

While the parallelism 
offered by the numerous disks of the cluster can alleviate the I/O bandwidth 
problem, it does not really address the latency issue that is largely limited 
by seek, rotational and network transfer costs. Caching data blocks in main 
memory is a well-known way of reducing I/O latencies, provided we can achieve 
good hit rates. I/O caching is typically done in software, and the overheads 
of cache lookup and maintenance could become quite high. Further, we may need 
multiple levels of such caches to reduce capacity misses for such large 
data-sets. On such systems, the cost of going to the upper levels of the cache 
and not finding the data there (before going to disk) might be quite 
substantial. Consequently, it becomes important to intelligently determine what
blocks to place in caches and when to avoid or bypass the caches whose lookup 
costs are significantly higher on I/O requests. However, this largely depends 
on the application's data access patterns and hence we need compiler-based/static 
and runtime techniques that automatically try to identify frequently 
used blocks and place them on caches that are closer to the client nodes.
A detailed description and evaluation of our prototype ``discretionary caching'' system
built atop a popularly used parallel file-system (PVFS) on Linux clusters
was published in IEEE Cluster 2002 and IEEE/ACM CCGrid 2003.

High-bandwidth I/O continues to play a critical role
in the performance of numerous scientific applications that manipulate
large data sets.
With little or no information about the
workloads to be supported, a file system designer has to often make
a hard choice regarding the consistency policies which can affect performance
adversely in some situations.
Leaving the choice and granularity 
of consistency policies to the user at open/mount time provides an
attractive way of providing the best of all worlds. The level of sharing when 
viewed at a file granularity in parallel computing
environments is much higher than that observed in network file 
systems, making consistency more important.
Enforcement of such consistency can, however, conflict with performance
and scalability goals. To address some of these deficiencies, I designed and
implemented a file-store, CAPFS (Content
Addressable Parallel File System), that
allows the user to define consistency semantic policies at runtime.
A client-side plug-in architecture based on user-written plug-ins 
leaves the choice of consistency policies to the end-user. A detailed description
of our prototype system was published in USENIX FAST 2005.

Based on the above research that I have done so far, I see several interesting
directions that I would like to pursue. Parallel file-systems have long been the vehicle
for delivering the much needed performance due to their simplicity of interfaces,
setup and management. Although POSIX has been the standard of choice that most
disk-based file-systems adher to, it is becoming increasingly apparent that
it may not be appropriate from a performance standpoint in a parallel file-system environment. 
I have been involved with a working group that is advocating augmentations to the POSIX
interfaces and standards that would allow implementors more leeway in exploiting performance.
However, performance is not the sole criterion for enabling many of these mission critical applications.
For instance, the vast amounts of data generated by many scientific experiments needs to be analyzed, interpreted,
documented in order to create and extract knowledge bases that can be used for meaningful comparisons
of results. Further, these knowledge bases may need to be archived, annotated and made accessible
to the scientific community.Consequently, new mechanisms, interfaces are needed in the parallel
file-system to manage this data throughout its life-cycle. 

My research work has involved a good amount of survey and 
analysis of existing solutions for problems, improvements and/or a better 
solution, a detailed understanding of pros and cons of the improvements, and 
technology transfer of the results into usable products. Towards this goal, 
my work uses several implementation techniques to improve the 
performance of today's large-scale scientific applications by improving cache 
hit rates or reducing page-faults/cache misses, and leveraging weaker
consistency policies. This in turn has led to a good overall understanding
of the various components constituting the high-performance I/O software
stack. My collaboration with researchers at Argonne 
National Laboratory have also helped me get a hands-on perspective of various problems
and solutions involved in these techniques. It has helped pave a thorough 
groundwork for my future research and I expect to make the most out of it.

\end{document}
